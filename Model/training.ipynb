{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defedc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from model import neural_model as nm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db13077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_extracted_a0f66459.csv')\n",
    "electrode_col_names = [col for col in df.columns if 'GRID' in col ]\n",
    "X = df[electrode_col_names]\n",
    "Y = df['mvmt']\n",
    "Y = (Y=='r_arm_1').astype(int)\n",
    "num_samples = len(Y)\n",
    "\n",
    "\n",
    "train_X = X[:int(num_samples*.8)]\n",
    "test_X = X[int(num_samples*.8):int(num_samples*.9)]\n",
    "val_X = X[int(num_samples*.9):]\n",
    "train_Y = Y[:int(num_samples*.8)]\n",
    "test_Y = Y[int(num_samples*.8):int(num_samples*.9)]\n",
    "val_Y = Y[int(num_samples*.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0428e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ecog_dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.data = x\n",
    "        self.keys = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.data.iloc[index]), torch.tensor([self.keys.iloc[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581f6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y,stratify=Y, test_size=0.30)\n",
    "test_X, val_X, test_Y, val_Y = train_test_split(test_X, test_Y, stratify=test_Y, test_size=1.0/3.0)\n",
    "\n",
    "trainset = ecog_dataset(train_X, train_Y)\n",
    "testset = ecog_dataset(test_X, test_Y)\n",
    "valset = ecog_dataset(val_X, val_Y)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True) #dataset to train on (80% data)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=True) #dataset to test each epoch on (10% data)\n",
    "validloader = DataLoader(valset, batch_size=100, shuffle=True) #dataset to validate perf on (10% data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4560725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define network and params\n",
    "net = nm(64)\n",
    "\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=.001)\n",
    "best_loss = 99999\n",
    "best_net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e264ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 train loss:  0.6210436969995499 test loss:  0.6322360038757324\n",
      "Epoch:  1 train loss:  0.6130714863538742 test loss:  0.6505784839391708\n",
      "Epoch:  2 train loss:  0.6224280397097269 test loss:  0.6470284312963486\n",
      "Epoch:  3 train loss:  0.6286038011312485 test loss:  0.6215077787637711\n",
      "Epoch:  4 train loss:  0.6279243926207224 test loss:  0.6793808043003082\n",
      "Epoch:  5 train loss:  0.6233350535233816 test loss:  0.6353797167539597\n",
      "Epoch:  6 train loss:  0.6172137210766474 test loss:  0.6344038248062134\n",
      "Epoch:  7 train loss:  0.6144675016403198 test loss:  0.6530693471431732\n",
      "Epoch:  8 train loss:  0.6112454434235891 test loss:  0.6525371074676514\n",
      "Epoch:  9 train loss:  0.6159925311803818 test loss:  0.640646830201149\n",
      "Epoch:  10 train loss:  0.6172730525334676 test loss:  0.6205847263336182\n",
      "Epoch:  11 train loss:  0.6133063832918803 test loss:  0.6486046612262726\n",
      "Epoch:  12 train loss:  0.6138452291488647 test loss:  0.6478706002235413\n",
      "Epoch:  13 train loss:  0.6200531125068665 test loss:  0.629565492272377\n",
      "Epoch:  14 train loss:  0.6203182190656662 test loss:  0.6521566957235336\n",
      "Epoch:  15 train loss:  0.607675239443779 test loss:  0.6568680852651596\n",
      "Epoch:  16 train loss:  0.6231191605329514 test loss:  0.6292950958013535\n",
      "Epoch:  17 train loss:  0.6166612307230631 test loss:  0.6359821707010269\n",
      "Epoch:  18 train loss:  0.6120608250300089 test loss:  0.6526863276958466\n",
      "Epoch:  19 train loss:  0.6117959568897883 test loss:  0.6560690253973007\n",
      "Epoch:  20 train loss:  0.6103967577219009 test loss:  0.633328452706337\n",
      "Epoch:  21 train loss:  0.6159230868021647 test loss:  0.6499069631099701\n",
      "Epoch:  22 train loss:  0.6165015151103338 test loss:  0.6260550022125244\n",
      "Epoch:  23 train loss:  0.6193422774473826 test loss:  0.6343173831701279\n",
      "Epoch:  24 train loss:  0.605444093545278 test loss:  0.6490080505609512\n",
      "Epoch:  25 train loss:  0.611818919579188 test loss:  0.6581624150276184\n",
      "Epoch:  26 train loss:  0.6157130897045135 test loss:  0.6496026962995529\n",
      "Epoch:  27 train loss:  0.6111011703809103 test loss:  0.6336807608604431\n",
      "Epoch:  28 train loss:  0.6046575158834457 test loss:  0.6552202254533768\n",
      "Epoch:  29 train loss:  0.6103167434533437 test loss:  0.6458735018968582\n",
      "Epoch:  30 train loss:  0.6223150342702866 test loss:  0.627647802233696\n",
      "Epoch:  31 train loss:  0.6038891871770223 test loss:  0.6468323022127151\n",
      "Epoch:  32 train loss:  0.6109198778867722 test loss:  0.6456421613693237\n",
      "Epoch:  33 train loss:  0.6153229673703512 test loss:  0.6507882177829742\n",
      "Epoch:  34 train loss:  0.6140350302060446 test loss:  0.6404793113470078\n",
      "Epoch:  35 train loss:  0.6125327398379644 test loss:  0.6342502236366272\n",
      "Epoch:  36 train loss:  0.6178770909706751 test loss:  0.6398102939128876\n",
      "Epoch:  37 train loss:  0.6169295807679495 test loss:  0.6301706880331039\n",
      "Epoch:  38 train loss:  0.6045617610216141 test loss:  0.6303007155656815\n",
      "Epoch:  39 train loss:  0.6153045097986857 test loss:  0.6533254086971283\n",
      "Epoch:  40 train loss:  0.615749458471934 test loss:  0.6236528754234314\n",
      "Epoch:  41 train loss:  0.6084714184204737 test loss:  0.6370964646339417\n",
      "Epoch:  42 train loss:  0.6144733627637228 test loss:  0.638722613453865\n",
      "Epoch:  43 train loss:  0.6095094134410223 test loss:  0.6166355758905411\n",
      "Epoch:  44 train loss:  0.6135245909293493 test loss:  0.6310875862836838\n",
      "Epoch:  45 train loss:  0.6110454897085825 test loss:  0.6214601248502731\n",
      "Epoch:  46 train loss:  0.607594350973765 test loss:  0.6181127727031708\n",
      "Epoch:  47 train loss:  0.615538572271665 test loss:  0.6494737416505814\n",
      "Epoch:  48 train loss:  0.6174669613440832 test loss:  0.6186915934085846\n",
      "Epoch:  49 train loss:  0.6068839927514394 test loss:  0.629874125123024\n",
      "Epoch:  50 train loss:  0.6187037775913874 test loss:  0.6141308099031448\n",
      "Epoch:  51 train loss:  0.6118638863166174 test loss:  0.6225775182247162\n",
      "Epoch:  52 train loss:  0.6093213905890783 test loss:  0.6202028691768646\n",
      "Epoch:  53 train loss:  0.6116576790809631 test loss:  0.6311202794313431\n",
      "Epoch:  54 train loss:  0.6157080282767614 test loss:  0.6364737451076508\n",
      "new best model!\n",
      "Epoch:  55 train loss:  0.6146538356939951 test loss:  0.6041340008378029\n",
      "Epoch:  56 train loss:  0.6136406511068344 test loss:  0.6443061232566833\n",
      "Epoch:  57 train loss:  0.6092847734689713 test loss:  0.629360243678093\n",
      "Epoch:  58 train loss:  0.6049203922351202 test loss:  0.6401098817586899\n",
      "Epoch:  59 train loss:  0.6141101370255152 test loss:  0.6688094437122345\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "#train\n",
    "for epoch in range(60):\n",
    "    running_loss = 0.0\n",
    "    train_count = 0\n",
    "    #net = copy.deepcopy(best_net)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        net.train()\n",
    "        inputs, labels = data\n",
    "        #if(labels.item() == 1):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs.float())\n",
    "        #print(outputs)\n",
    "        loss = loss_func(outputs.float(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        train_count += 1\n",
    "    #do epoch test on separate test set\n",
    "    test_loss = 0.0\n",
    "    test_count = 0\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs.float())\n",
    "        loss = loss_func(torch.round(outputs), labels.float())\n",
    "        test_loss += loss.item()\n",
    "        test_count += 1\n",
    "    if test_loss/test_count < best_loss:\n",
    "        best_loss = test_loss/test_count\n",
    "        #best_net = copy.deepcopy(net)\n",
    "        print('new best model!')\n",
    "    print(\"Epoch: \", epoch, 'train loss: ', running_loss/train_count, \n",
    "          'test loss: ', test_loss/test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc6bb837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fc1.weight', tensor([[ 0.1241, -0.0843, -0.1125,  ..., -0.0874, -0.1034, -0.1154],\n",
      "        [ 0.0672,  0.1450,  0.0301,  ...,  0.0862,  0.0861,  0.0212],\n",
      "        [-0.1922,  0.0761, -0.1744,  ...,  0.0087, -0.0748, -0.0502],\n",
      "        ...,\n",
      "        [-0.2329, -0.1717, -0.1205,  ..., -0.0254,  0.0066, -0.1323],\n",
      "        [ 0.1443,  0.0582, -0.0565,  ...,  0.1013,  0.0073,  0.0324],\n",
      "        [-0.1584, -0.2285,  0.0037,  ..., -0.0365, -0.0002,  0.0006]])), ('fc1.bias', tensor([-9.6596e-02, -1.5201e-02, -1.8509e-02,  2.9181e-02,  1.1015e-02,\n",
      "         1.1403e-03, -1.1423e-02, -9.1567e-05, -5.0528e-03, -6.5650e-03,\n",
      "        -1.8195e-02, -1.4723e-02, -1.3543e-02, -2.2379e-02, -4.9507e-03,\n",
      "        -7.3408e-05, -1.0404e-02,  3.0550e-03, -1.2495e-01, -3.3072e-02,\n",
      "         1.4398e-02, -1.0310e-02,  2.6151e-02, -2.4285e-02,  5.8300e-02,\n",
      "        -1.2565e-01,  2.8762e-03,  1.5452e-02, -1.4524e-02,  1.5347e-02,\n",
      "        -3.1394e-03, -1.5359e-02, -1.2894e-02, -2.9385e-02,  1.0337e-02,\n",
      "        -2.6151e-02,  7.3298e-03, -1.7437e-02, -6.6497e-03, -2.6078e-02,\n",
      "        -4.6364e-03, -1.2893e-02, -2.5695e-02,  2.7863e-02,  9.7798e-04,\n",
      "         7.2826e-03, -3.1215e-02,  2.8167e-03, -2.8910e-02, -5.8596e-04,\n",
      "        -8.4267e-02, -2.1500e-02, -1.6139e-02,  3.1056e-02,  3.9994e-03,\n",
      "        -2.4553e-02,  1.8379e-02, -9.5674e-03, -5.9378e-02,  1.2641e-02,\n",
      "         5.7073e-03,  1.8102e-02,  2.7811e-02, -1.2323e-02, -2.9792e-02,\n",
      "         1.1787e-02,  1.6560e-02,  2.3175e-02, -1.4657e-03,  1.0990e-02,\n",
      "         1.8966e-02, -2.1596e-02, -2.6660e-03,  1.8358e-02, -7.0321e-03,\n",
      "         1.1730e-02,  2.2376e-02, -3.3313e-03, -9.6968e-03, -1.7327e-02,\n",
      "        -2.0885e-02, -4.5022e-03, -1.8418e-02, -1.1826e-02,  2.1115e-02,\n",
      "         3.4977e-03, -4.7655e-03, -6.7966e-03, -7.8320e-03,  4.0922e-02,\n",
      "        -2.5393e-02, -1.8302e-03, -5.0748e-03, -1.7204e-02,  1.6724e-03,\n",
      "        -5.6018e-03])), ('fc2.weight', tensor([[-0.0017,  0.1398,  0.3089,  ...,  0.1299,  0.1025,  0.1586],\n",
      "        [ 0.0430, -0.0302,  0.0614,  ..., -0.0716, -0.0049,  0.0180],\n",
      "        [-0.0543, -0.0755,  0.0208,  ..., -0.0234, -0.0415, -0.0748],\n",
      "        ...,\n",
      "        [ 0.1008,  0.0306, -0.0852,  ..., -0.1171,  0.0885, -0.1055],\n",
      "        [-0.0866, -0.0412,  0.0878,  ...,  0.1325,  0.0714,  0.1598],\n",
      "        [ 0.0105, -0.1257, -0.2181,  ..., -0.2400, -0.0104, -0.1819]])), ('fc2.bias', tensor([-0.0071, -0.0102, -0.0095,  0.0153, -0.0137, -0.0676,  0.0173, -0.0318,\n",
      "        -0.0135, -0.0189, -0.0031, -0.0642,  0.0098, -0.0892, -0.0264, -0.0505,\n",
      "         0.0301,  0.0029, -0.0268, -0.0010, -0.0481,  0.0268, -0.0681, -0.0294,\n",
      "        -0.0091,  0.0498, -0.0365, -0.0349,  0.0667, -0.0063, -0.0081,  0.0368,\n",
      "        -0.0316, -0.0029, -0.1325,  0.0209, -0.0228, -0.0041, -0.0637, -0.0527,\n",
      "         0.0687, -0.0414,  0.0052,  0.0371,  0.0332,  0.0132,  0.0522,  0.0175,\n",
      "        -0.0246,  0.0341,  0.0279, -0.0039, -0.0039, -0.0040, -0.0795, -0.0775,\n",
      "         0.0535, -0.0875,  0.0433,  0.0014, -0.0176, -0.0331, -0.0734,  0.0999])), ('fc3.weight', tensor([[ 0.1993,  0.1197,  0.0411,  ..., -0.0388,  0.2084, -0.0309],\n",
      "        [-0.0127,  0.0344,  0.0666,  ..., -0.0916,  0.0247, -0.1046],\n",
      "        [-0.0400, -0.0481, -0.0149,  ..., -0.0063, -0.0508,  0.0168],\n",
      "        ...,\n",
      "        [ 0.0694,  0.0579,  0.1148,  ..., -0.0550,  0.1203, -0.1463],\n",
      "        [ 0.1148, -0.0623,  0.0216,  ..., -0.0518,  0.0144,  0.1166],\n",
      "        [ 0.0368,  0.0727, -0.1192,  ...,  0.0859, -0.0188, -0.1120]])), ('fc3.bias', tensor([-0.0396, -0.0255, -0.0212,  0.0957, -0.1215, -0.0018,  0.1503, -0.0132,\n",
      "         0.0758, -0.0725, -0.0237, -0.0322, -0.0459, -0.0303, -0.0872, -0.0313,\n",
      "         0.0731, -0.0038,  0.0262,  0.0247, -0.0995, -0.0791, -0.0131, -0.0243,\n",
      "        -0.0017, -0.0735, -0.1103,  0.0305,  0.0158, -0.0305, -0.0163, -0.0528])), ('fc4.weight', tensor([[ 0.2819, -0.1323,  0.1902,  ...,  0.1200, -0.0178, -0.1224],\n",
      "        [ 0.1799, -0.1017, -0.0994,  ...,  0.0667, -0.0503, -0.1393],\n",
      "        [ 0.0023,  0.1172, -0.1008,  ...,  0.2127, -0.0548, -0.0430],\n",
      "        ...,\n",
      "        [ 0.2611, -0.1300,  0.1545,  ...,  0.2345,  0.1120,  0.0350],\n",
      "        [ 0.1980,  0.0422, -0.0806,  ...,  0.0882, -0.0258, -0.1620],\n",
      "        [ 0.0130,  0.1455, -0.1383,  ...,  0.0743,  0.1529, -0.1036]])), ('fc4.bias', tensor([ 0.0911, -0.0631,  0.0294,  0.1454,  0.1108,  0.1075, -0.1288,  0.2751,\n",
      "        -0.0206,  0.0067,  0.1825,  0.0972, -0.0882, -0.0825, -0.0393, -0.1097,\n",
      "        -0.0334, -0.0424,  0.1713, -0.0784, -0.0431, -0.1008, -0.0499, -0.0108,\n",
      "        -0.0841, -0.1476,  0.1796,  0.0070, -0.1259, -0.0616,  0.2330,  0.2102,\n",
      "        -0.0649, -0.0455, -0.1133, -0.0145, -0.1108,  0.1417, -0.0892, -0.1685,\n",
      "        -0.0348, -0.0920, -0.0917, -0.0149,  0.0987, -0.1554, -0.0724, -0.1315,\n",
      "         0.0365, -0.0539,  0.2018,  0.1785,  0.1771,  0.2532, -0.0455, -0.0183,\n",
      "        -0.0429, -0.0344,  0.0108,  0.1672, -0.1647,  0.0613,  0.1300,  0.1159])), ('fc5.weight', tensor([[ 0.1669,  0.0490, -0.0084,  ...,  0.1508,  0.0950, -0.0675],\n",
      "        [ 0.1914,  0.1565,  0.0601,  ...,  0.1687,  0.1648,  0.0260],\n",
      "        [ 0.1309, -0.0244,  0.0764,  ...,  0.0386, -0.0262, -0.0192],\n",
      "        ...,\n",
      "        [ 0.1249,  0.0405, -0.1500,  ..., -0.0973,  0.1428, -0.0295],\n",
      "        [ 0.0245, -0.1691, -0.0807,  ..., -0.0309,  0.1191,  0.0897],\n",
      "        [-0.0480, -0.0727, -0.1079,  ...,  0.0115, -0.1031, -0.1027]])), ('fc5.bias', tensor([-0.0873, -0.0082,  0.0314,  0.0855,  0.1930, -0.1174,  0.1019, -0.0087,\n",
      "         0.0335, -0.0799, -0.1023, -0.1016,  0.1252, -0.1176, -0.0648,  0.0349,\n",
      "        -0.0585,  0.0829,  0.2966, -0.0304, -0.0710, -0.0061,  0.2365, -0.0314,\n",
      "        -0.0239, -0.1014,  0.0128, -0.0063, -0.1248,  0.0134, -0.0127, -0.0752,\n",
      "        -0.0756,  0.0132, -0.0316,  0.0347,  0.0442,  0.0326,  0.0190, -0.0990,\n",
      "        -0.0398, -0.0383, -0.0369, -0.0914, -0.0333,  0.2721,  0.2095, -0.1068])), ('fc6.weight', tensor([[-0.0242,  0.1066, -0.0836,  ..., -0.0636, -0.0837, -0.1338],\n",
      "        [-0.0105,  0.1731,  0.0060,  ..., -0.0559,  0.0939,  0.1187],\n",
      "        [ 0.1007, -0.1362, -0.0409,  ..., -0.1208, -0.0611, -0.0721],\n",
      "        ...,\n",
      "        [ 0.2499,  0.0047,  0.1736,  ...,  0.0388,  0.0414,  0.1091],\n",
      "        [ 0.0492,  0.1356,  0.1015,  ..., -0.1206, -0.1290, -0.0182],\n",
      "        [-0.0721, -0.1147, -0.0330,  ..., -0.1039,  0.0084,  0.0107]])), ('fc6.bias', tensor([-0.0719, -0.0666, -0.1304,  0.2129, -0.0334, -0.0743,  0.2426,  0.0701,\n",
      "        -0.0420,  0.2943, -0.0163,  0.2364,  0.0033, -0.0014, -0.0355,  0.2770,\n",
      "        -0.0423,  0.0936,  0.0362,  0.0181,  0.0300, -0.0940,  0.0464,  0.0056,\n",
      "        -0.1117, -0.1179, -0.0109, -0.0156,  0.0994,  0.1047,  0.0877, -0.0976])), ('fc7.weight', tensor([[-0.1524,  0.1697,  0.1239, -0.3859,  0.0533,  0.0069, -0.3857,  0.1676,\n",
      "          0.1116, -0.3407,  0.1649, -0.2648,  0.1385, -0.0845,  0.1250, -0.2868,\n",
      "          0.1331,  0.1220,  0.1290,  0.0514,  0.1320, -0.0255,  0.0981, -0.0424,\n",
      "         -0.1350,  0.1742,  0.1464,  0.0985,  0.1077,  0.1696,  0.0979,  0.0513]])), ('fc7.bias', tensor([-0.1528]))])\n",
      "<class 'type'>\n"
     ]
    }
   ],
   "source": [
    "from model import neural_model as nm\n",
    "import torch\n",
    "best_net = nm(64)\n",
    "best_net.load_state_dict(torch.load('curr_best.pyt'))\n",
    "print(torch.load('curr_best.pyt'))\n",
    "print(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01dbf1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
      "[0.6241171956062317, 0.06185154244303703, 1.0, 0.002084453823044896, 1.0, 0.5700456500053406, 1.0, 1.0, 0.9492681622505188, 0.252703994512558, 1.0, 1.0, 1.0, 1.0, 0.89503413438797, 0.02312004566192627, 0.004640539642423391, 0.26173868775367737, 0.4711877405643463, 0.009015600197017193, 1.0, 0.8429558873176575, 0.22323746979236603, 1.0, 1.0, 1.0, 0.33360981941223145, 0.0, 0.04098689556121826, 0.872113049030304, 2.674261668289546e-05, 1.0, 0.7485087513923645, 0.0, 0.22146910429000854, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.029281815513968468, 0.07939688116312027, 0.3130021393299103, 1.0, 1.0, 0.8992173075675964, 1.0, 1.0, 1.0, 0.35752370953559875, 1.0, 1.0, 0.20039379596710205, 1.0, 0.0, 0.17286622524261475, 0.5173518061637878, 0.17172719538211823, 0.22495567798614502, 0.6058283448219299, 1.0, 0.04841570183634758, 0.01642950437963009, 1.0, 1.0, 0.04056668281555176, 0.0, 0.051141221076250076, 0.6871843338012695, 1.0, 0.14685940742492676, 0.8338636755943298, 0.3783925473690033, 0.12209673970937729, 0.11895612627267838, 1.0, 0.539776623249054, 1.0, 0.02926814556121826, 0.7314483523368835, 0.3199848234653473, 0.0, 1.0, 0.0071332454681396484, 0.9785676002502441, 1.0, 1.0, 0.22586025297641754, 0.4120905101299286, 1.0, 0.065767802298069, 1.0, 0.10734089463949203, 0.018474260345101357, 1.0, 0.0, 0.4082825183868408, 0.0044371685944497585, 1.0, 1.0, 0.14591622352600098, 0.916121780872345, 0.012432019226253033, 0.12663233280181885, 0.026567181572318077, 0.6823317408561707, 0.0, 0.17319746315479279, 1.0, 1.0, 0.8786506652832031, 0.5473808646202087, 0.42058631777763367, 0.11883655935525894, 1.0, 0.14094571769237518, 0.0, 0.21361704170703888, 1.0, 1.0, 0.008217930793762207, 0.8771106600761414, 0.7195430397987366, 1.0, 1.0, 1.0, 0.0, 0.22710977494716644, 1.0, 1.0, 0.051061272621154785, 0.11347067356109619, 1.0, 0.011707663536071777, 1.0, 0.0, 0.013766963966190815, 0.5657021999359131, 0.33041104674339294, 1.0, 0.5711491703987122, 0.00880305003374815, 0.18517686426639557, 0.11314579099416733, 1.0, 0.0, 1.0, 0.6244019865989685, 0.17335182428359985, 0.8267605900764465, 0.03621427342295647, 1.0, 0.026076355949044228, 0.7008569240570068, 0.4356153905391693, 1.0, 0.08031753450632095, 1.0, 0.11116206645965576, 0.0, 0.0830628052353859, 0.3441457450389862, 0.8111769556999207, 0.8568463325500488, 0.011745135299861431, 0.0007404486532323062, 0.020948251709342003]\n",
      "validation loss:  0.5789957940578461\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "validate_loss = 0.0\n",
    "validate_count = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i, data in enumerate(validloader, 0):\n",
    "    best_net.eval()\n",
    "    inputs, labels = data\n",
    "    outputs = best_net(inputs.float())\n",
    "    loss = loss_func(outputs, labels.float())\n",
    "    for item in outputs:\n",
    "        y_pred.append(item.item())\n",
    "    for item in labels:\n",
    "        y_true.append(item.item())\n",
    "    validate_loss += loss.item()\n",
    "    validate_count += 1\n",
    "print(y_true)\n",
    "print(y_pred)\n",
    "print('validation loss: ', validate_loss / validate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef109256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "[1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
      "0.7345641182779225\n",
      "0.7202380952380952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "y_pred_round = []\n",
    "for pred in y_pred: #keep the network outputs within acceptable bounds\n",
    "    y_pred_round.append(min(max(round(pred), 0),1))\n",
    "print(y_pred_round)\n",
    "print(y_true)\n",
    "print(balanced_accuracy_score(y_true, y_pred_round))\n",
    "print(accuracy_score(y_true, y_pred_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fab63194",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_net.state_dict(), 'curr_best.pyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570d939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
