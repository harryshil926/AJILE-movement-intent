{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defedc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from model import neural_model as nm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db13077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_extracted_a0f66459.csv')\n",
    "electrode_col_names = [col for col in df.columns if 'GRID' in col ]\n",
    "X = df[electrode_col_names]\n",
    "Y = df['mvmt']\n",
    "Y = (Y=='r_arm_1').astype(int)\n",
    "num_samples = len(Y)\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y,stratify=Y, test_size=0.20)\n",
    "test_X, val_X, test_Y, val_Y = train_test_split(test_X, test_Y, stratify=test_Y, test_size=0.50)\n",
    "\n",
    "#train_X = X[:int(num_samples*.8)]\n",
    "#test_X = X[int(num_samples*.8):int(num_samples*.9)]\n",
    "#val_X = X[int(num_samples*.9):]\n",
    "#train_Y = Y[:int(num_samples*.8)]\n",
    "#test_Y = Y[int(num_samples*.8):int(num_samples*.9)]\n",
    "#val_Y = Y[int(num_samples*.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0428e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ecog_dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.data = x\n",
    "        self.keys = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.data.iloc[index]), torch.tensor([self.keys.iloc[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581f6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ecog_dataset(train_X, train_Y)\n",
    "testset = ecog_dataset(test_X, test_Y)\n",
    "valset = ecog_dataset(val_X, val_Y)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True) #dataset to train on (80% data)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=True) #dataset to test each epoch on (10% data)\n",
    "validloader = DataLoader(valset, batch_size=100, shuffle=True) #dataset to validate perf on (10% data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4560725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define network and params\n",
    "net = nm(64)\n",
    "\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=.001)\n",
    "best_loss = 99999\n",
    "best_net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e264ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best model!\n",
      "Epoch:  0 train loss:  0.6531955940382821 test loss:  0.6931471526622772\n",
      "new best model!\n",
      "Epoch:  1 train loss:  0.655912492956434 test loss:  0.672085165977478\n",
      "Epoch:  2 train loss:  0.6521646082401276 test loss:  0.6814969480037689\n",
      "Epoch:  3 train loss:  0.6533336213656834 test loss:  0.6767911016941071\n",
      "new best model!\n",
      "Epoch:  4 train loss:  0.6518688542502267 test loss:  0.660320520401001\n",
      "Epoch:  5 train loss:  0.6521834305354527 test loss:  0.6697321832180023\n",
      "Epoch:  6 train loss:  0.6534948987620217 test loss:  0.6720851957798004\n",
      "Epoch:  7 train loss:  0.6507259437016079 test loss:  0.6673793196678162\n",
      "Epoch:  8 train loss:  0.6508706339768001 test loss:  0.6697322130203247\n",
      "Epoch:  9 train loss:  0.6485874312264579 test loss:  0.6720851957798004\n",
      "Epoch:  10 train loss:  0.6477182635239193 test loss:  0.6626733541488647\n",
      "Epoch:  11 train loss:  0.6459807881287166 test loss:  0.6767910420894623\n",
      "Epoch:  12 train loss:  0.6437421824250903 test loss:  0.681632936000824\n",
      "new best model!\n",
      "Epoch:  13 train loss:  0.6387424554143634 test loss:  0.6547496318817139\n",
      "Epoch:  14 train loss:  0.6401823120457786 test loss:  0.6834732592105865\n",
      "Epoch:  15 train loss:  0.6366430648735592 test loss:  0.6722842156887054\n",
      "new best model!\n",
      "Epoch:  16 train loss:  0.6392970383167267 test loss:  0.6510365605354309\n",
      "Epoch:  17 train loss:  0.633081431899752 test loss:  0.6669493019580841\n",
      "Epoch:  18 train loss:  0.637497786964689 test loss:  0.6822429597377777\n",
      "Epoch:  19 train loss:  0.6330933315413338 test loss:  0.6729693412780762\n",
      "Epoch:  20 train loss:  0.6353729707854134 test loss:  0.6566232144832611\n",
      "new best model!\n",
      "Epoch:  21 train loss:  0.6327310417379651 test loss:  0.6454501152038574\n",
      "new best model!\n",
      "Epoch:  22 train loss:  0.6239022782870701 test loss:  0.6260088980197906\n",
      "Epoch:  23 train loss:  0.6335856020450592 test loss:  0.6641904413700104\n",
      "Epoch:  24 train loss:  0.6372885406017303 test loss:  0.64357990026474\n",
      "Epoch:  25 train loss:  0.6259048368249621 test loss:  0.6705328226089478\n",
      "Epoch:  26 train loss:  0.6358825266361237 test loss:  0.6578456461429596\n",
      "Epoch:  27 train loss:  0.6278448232582637 test loss:  0.6800493597984314\n",
      "Epoch:  28 train loss:  0.6254665468420301 test loss:  0.6535374820232391\n",
      "Epoch:  29 train loss:  0.6334954585347857 test loss:  0.6567005217075348\n",
      "Epoch:  30 train loss:  0.6202526262828282 test loss:  0.6576157808303833\n",
      "Epoch:  31 train loss:  0.629075003521783 test loss:  0.6504844129085541\n",
      "Epoch:  32 train loss:  0.6209614319460732 test loss:  0.6537300944328308\n",
      "Epoch:  33 train loss:  0.6206155504499163 test loss:  0.6328540742397308\n",
      "Epoch:  34 train loss:  0.6250250552381788 test loss:  0.6522790491580963\n",
      "Epoch:  35 train loss:  0.6257952196257455 test loss:  0.6626912951469421\n",
      "Epoch:  36 train loss:  0.6249066761561802 test loss:  0.6358694136142731\n",
      "Epoch:  37 train loss:  0.617163645369666 test loss:  0.688869297504425\n",
      "Epoch:  38 train loss:  0.6326867810317448 test loss:  0.6752960085868835\n",
      "Epoch:  39 train loss:  0.6265795358589717 test loss:  0.6375944316387177\n",
      "Epoch:  40 train loss:  0.6255434027739933 test loss:  0.6530742645263672\n",
      "Epoch:  41 train loss:  0.6218597420624324 test loss:  0.672265887260437\n",
      "Epoch:  42 train loss:  0.6199264909539904 test loss:  0.6610579490661621\n",
      "Epoch:  43 train loss:  0.6248122453689575 test loss:  0.6612734198570251\n",
      "Epoch:  44 train loss:  0.6167019137314388 test loss:  0.6752597093582153\n",
      "Epoch:  45 train loss:  0.6218117943831852 test loss:  0.6413933038711548\n",
      "Epoch:  46 train loss:  0.6164738621030535 test loss:  0.6390453577041626\n",
      "Epoch:  47 train loss:  0.6211396838937487 test loss:  0.6653155088424683\n",
      "Epoch:  48 train loss:  0.620062027658735 test loss:  0.6573546826839447\n",
      "Epoch:  49 train loss:  0.6164634525775909 test loss:  0.6305699646472931\n",
      "Epoch:  50 train loss:  0.6159446111747197 test loss:  0.6433976888656616\n",
      "Epoch:  51 train loss:  0.619958119732993 test loss:  0.6626701056957245\n",
      "Epoch:  52 train loss:  0.619457198040826 test loss:  0.6641785502433777\n",
      "Epoch:  53 train loss:  0.6115442556994302 test loss:  0.6620490849018097\n",
      "Epoch:  54 train loss:  0.6167876890727452 test loss:  0.6883455812931061\n",
      "Epoch:  55 train loss:  0.614341561283384 test loss:  0.6524747610092163\n",
      "Epoch:  56 train loss:  0.6234905081135886 test loss:  0.6666150093078613\n",
      "Epoch:  57 train loss:  0.6147219708987645 test loss:  0.6527950465679169\n",
      "Epoch:  58 train loss:  0.61629347716059 test loss:  0.6645628213882446\n",
      "Epoch:  59 train loss:  0.6206355435507638 test loss:  0.6641291975975037\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "#train\n",
    "for epoch in range(60):\n",
    "    running_loss = 0.0\n",
    "    train_count = 0\n",
    "    #net = copy.deepcopy(best_net)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        net.train()\n",
    "        inputs, labels = data\n",
    "        #if(labels.item() == 1):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs.float())\n",
    "        #print(outputs)\n",
    "        loss = loss_func(outputs.float(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        train_count += 1\n",
    "    #do epoch test on separate test set\n",
    "    test_loss = 0.0\n",
    "    test_count = 0\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs.float())\n",
    "        loss = loss_func(torch.round(outputs), labels.float())\n",
    "        test_loss += loss.item()\n",
    "        test_count += 1\n",
    "    if test_loss/test_count < best_loss:\n",
    "        best_loss = test_loss/test_count\n",
    "        best_net = copy.deepcopy(net)\n",
    "        print('new best model!')\n",
    "    print(\"Epoch: \", epoch, 'train loss: ', running_loss/train_count, \n",
    "          'test loss: ', test_loss/test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01dbf1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1]\n",
      "[0.25887417793273926, 0.2576909363269806, 0.2576003670692444, 0.25725695490837097, 1.0, 0.5215379595756531, 0.25718677043914795, 1.0, 0.4778161942958832, 0.25729987025260925, 1.0, 1.0, 0.600465714931488, 0.27381980419158936, 0.2725762724876404, 0.2577058672904968, 1.0, 0.25732579827308655, 0.25777342915534973, 0.2562524378299713, 1.0, 0.3278510868549347, 0.25738486647605896, 0.25768572092056274, 0.44001269340515137, 0.44625625014305115, 0.25783470273017883, 0.38733914494514465, 0.7376481890678406, 0.45019373297691345, 0.258372962474823, 0.34791699051856995, 1.0, 0.2776889503002167, 0.25723880529403687, 0.3641357421875, 0.27365317940711975, 0.31867536902427673, 1.0, 0.2591134309768677, 0.26674893498420715, 0.2943190038204193, 0.2566289007663727, 0.25799766182899475, 0.2647685110569, 0.2576294243335724, 0.38673827052116394, 0.25689029693603516, 0.2569904625415802, 0.5099548697471619, 0.258289098739624, 0.7264133095741272, 0.2604120075702667, 0.2577836811542511, 0.25739696621894836, 0.2658650279045105, 0.25747963786125183, 0.257572740316391, 0.2571759819984436, 0.7535699009895325, 0.25601574778556824, 1.0, 0.7585287094116211, 0.2649243175983429, 0.2570597231388092, 1.0, 0.7216396331787109, 0.26633375883102417, 0.28877171874046326, 0.33465829491615295, 0.2574177086353302, 0.9136170744895935, 0.9863303303718567, 0.2800842821598053, 0.46662449836730957, 0.25751420855522156, 0.5152741074562073, 0.34147343039512634, 0.26563361287117004, 0.2713511288166046, 0.26083236932754517, 0.5196160674095154, 1.0, 0.25733089447021484, 0.25663456320762634, 1.0, 1.0, 1.0, 0.2569396197795868, 0.2572406828403473, 0.25966641306877136, 1.0, 0.25984665751457214, 0.2577314078807831, 0.25815102458000183, 0.257257878780365, 0.6889691352844238, 0.25700631737709045, 1.0, 0.25767675042152405, 0.2581234872341156, 0.2585962414741516, 0.2564839720726013, 0.25770434737205505, 0.2580295503139496, 0.46822455525398254, 0.2582307457923889, 0.25829604268074036, 0.4657425880432129, 0.25775888562202454, 0.25757524371147156, 1.0, 0.799849808216095, 0.5548334121704102, 0.577549934387207, 0.3710744082927704, 0.26670563220977783, 0.2607211172580719, 1.0, 0.8243310451507568, 1.0, 0.25709423422813416, 1.0, 0.26541441679000854, 0.25827792286872864, 0.2571023404598236, 1.0, 0.2574283480644226, 0.25799229741096497, 1.0, 1.0, 0.2569301426410675, 0.804014265537262, 0.35404983162879944, 0.25634464621543884, 0.2627491056919098, 0.25701624155044556, 1.0, 0.25683847069740295, 0.4008707106113434, 0.26965421438217163, 0.38927531242370605, 0.2580420970916748, 0.2568909525871277, 0.258495032787323, 0.2572552561759949, 0.26591652631759644, 0.43771466612815857, 0.8694660663604736, 0.25878670811653137, 0.26339587569236755, 0.258049875497818, 0.2578534781932831, 1.0, 0.33474722504615784, 1.0, 0.7729366421699524, 0.7222030758857727, 1.0, 0.5856292843818665, 1.0, 1.0, 0.25615227222442627, 0.261697381734848, 0.2580837905406952, 1.0, 0.25562697649002075, 1.0]\n",
      "validation loss:  0.6109615564346313\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "validate_loss = 0.0\n",
    "validate_count = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i, data in enumerate(validloader, 0):\n",
    "    best_net.eval()\n",
    "    inputs, labels = data\n",
    "    outputs = best_net(inputs.float())\n",
    "    loss = loss_func(outputs, labels.float())\n",
    "    for item in outputs:\n",
    "        y_pred.append(item.item())\n",
    "    for item in labels:\n",
    "        y_true.append(item.item())\n",
    "    validate_loss += loss.item()\n",
    "    validate_count += 1\n",
    "print(y_true)\n",
    "print(y_pred)\n",
    "print('validation loss: ', validate_loss / validate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef109256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1]\n",
      "[1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6833154588631837"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred_round = []\n",
    "for pred in y_pred: #keep the network outputs within acceptable bounds\n",
    "    y_pred_round.append(min(max(round(pred), 0),1))\n",
    "print(y_pred_round)\n",
    "print(y_true)\n",
    "balanced_accuracy_score(y_true, y_pred_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fab63194",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_net.state_dict(), 'curr_best.pyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570d939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
